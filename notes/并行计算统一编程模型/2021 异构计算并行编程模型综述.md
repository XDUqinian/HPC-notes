# 2021 异构计算并行编程模型综述

## 问题

- 异构并行计算需要解决的关键问题是什么？提高资源利用率、减少通信开销
- 异构体系架构的发展方向是什么？

## 内容概括

当前，科研工程等领域对算力需求日益增大，而摩尔定律逐渐失效，高性能计算需要计算体系结构的创新。一方面，计算机体系结构的规模增大，由单核转向多核并行计算，依靠多核集群集中分布式算力，通过规模化效应提升算力；另一方面是架构创新，将擅长不同领域的计算器件按一定的组织方式组成多核异构的系统，在组织的过程中要考虑异构器件之间的任务划分、调度、通信、存储、同步等机制问题，通过新的计算机体系架构将硬件性能发挥到极致。本文介绍了异构编程模型、异构编程模型优化方法，讨论了异构并行计算关键问题，总结了异构计算体系架构的研究方向。

## 异构并行编程模型与优化

异构编程模型将底层硬件抽象表示，提供统一编程接口，解决异构系统并行计算、存储、通信等一系列问题。

现有异构并行编程模型优化研究分为两种：从硬件底层优化出发，针对特定异构架构设计编程模型；基于现有编程框架改进或扩展。

**显式异构编程模型**

OpenCL、CUDA

采用 Host/Device 分工形式，Host 运行 CPU 的控制代码，Device 运行加速设备的代码。编程接口偏底层，对开发能力要求高，对并行程序的分析和验证比较困难。

对显式编程模型的优化研究是将复杂的编程接口简化，构建结构化的编程框架。

[一种面向异构计算的结构化并行编程框架]() 

[Out-of-core implementation for accelerator kernels on heterogeneous clouds  ]()

**制导式编程模型**

OpenACC、OpenMP、OpenHMPP

以注释形式告诉编译器并行代码区域位置，编译器根据制导语句生成代码、执行代码段、传输数据、执行同步操作。生成代码通过调用运行时系统管理硬件资源以及跨不同内存层级传输数据。

对制导式异构编程主要是基于内存的优化。

[An OpenMP programming toolkit for hybrid CPU/GPU clusters based on software unified memory ]()

**中间表示**

在生成执行机器码过程中，运行时系统优化代码操作能够有效提高系统性能，即中间表示技术。

[DeveloperNvidia CUDA 工 具 包](https://developer.nvidia.com/zh-cn/cuda-toolkit  )

[HSA](http://www.hsafoundation.com/  )

[GitHub-OpenMp/examples](https://github.com/RadeonOpenCompute/ROCm)

[SPIR](https://www.khronos.org/spir/)

**异构编程语言接口**

用易于理解的高级语言实现抽象编程语言到底层框架的映射。

非托管编程语言可以直接处理内存，通过源到源的编译器将类C语言转成 CUDA 或 OpenCL 代码，实现不同规模的异构底层映射。

[UPPA:面向异构众核系统的统一并行编程架构]()

[一种面向异构众核处理器的并行编译框架]()

[Parallel multiprocessing and scheduling on the heterogeneous Xeon+FPGA platform]()

[Panda: a compiler framework for concurrent CPU+GPU execution of 3D stencil computations on GPUaccelerated supercomputers]()

托管式编程语言的内存可由运行时系统自动管理，依赖高效的语言虚拟机、解释器和编译器执行。

**融合并行编程模型**

运行时系统自动为每个设备选择和部署合适的内核， 管理数据移动并隐藏启动细节。  

**虚拟化异构编程模型**

以虚拟化方式消除异构系统开发、设备内存空间和线程配置的复杂性。

## 思考

粗略浏览这篇论文，对现有的异构并行编程模型及其优化方法有了一个比较系统的了解。后续可以看看这篇论文提到的那些论文来做进一步的研究。
