# LoRAPrune

PRUNING MEETS LOW-RANK PARAMETER-EFFICIENT FINE-TUNING

==大型预训练模型LPM== 针对下游任务的微调虽然以及出现了==高效参数微调PEFT==方法，但这些微调后的模型仍然因为巨大的规模与计算成本，而难以部署。SOTA的神经网络剪枝方法大多通过计算参数的梯度衡量参数的重要程度，但LPM做PEFT微调时，因为涉及到参数冻结，所以无法进行梯度的计算。

本文基于LoRA PEFT方法，提出了 LoRAPrune，通过对低秩适应矩阵求梯度来近似原始权重矩阵的梯度，实现高效参数微调与依赖梯度的剪枝的结合。

## 思考

该方法将低秩分解与剪枝相结合，使得PEFT的同时可以剪枝。

那用这种方法直接对预训练模型做剪枝可以吗，会存在什么问题？
