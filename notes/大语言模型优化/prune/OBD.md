# Optimal Brain Damage

这是剪枝领域的一篇经典论文，读了几篇论文都引用了这篇论文，所以就找出来读了一下，觉得会有一些帮助。这篇论文的标题是 最优脑损伤，提出了一种找神经元中不重要的参数的方法。当时的很多人简单地认为，参数的重要性由幅度大小衡量，即便是现在也有人这么做。而本文的作者认为，参数的重要性应该利用将其从网络中删除后损失的改变量来衡量，且通过一定程度的近似，这种重要性衡量方式也比较好算。因为这篇论文比较老，所以主要是了解一下它的思想。

# method

将参数的重要性定义为删去该参数后目标函数的改变。我们可以对其进行泰勒展开。

$\delta E=\sum_i g_i\delta u_i^2+\frac{1}{2}\sum_i h_{ii}\delta u_i^2+\frac{1}{2}\sum_{i \neq j}h_{ij}\delta u_i \delta u_j+O(||\delta U||^3)$

上式就是一个多元函数的泰勒展开式，E 表示损失，U是参数向量。

$g_i=\frac{\partial E}{\partial u_i}$ 表示一阶偏导

$h_{ij}=\frac{\partial ^2 E}{\partial u_i \partial u_j}$ 表示二阶偏导，也是海森矩阵中的元素。

我们的目标就是找到一组参数，将其删去后，上式值最小。

为了便于计算，论文假设总的损失是每个参数造成的损失之和，也就是**参数之间对损失的影响是独立的**。

这种假设导致上式中的二阶混合偏导项被忽略不计，只需考虑海森矩阵中的对角线元素即可。

如果将问题放到训练之后，由于训练后参数已经收敛到目标函数达局部最小值，所以可以认为一阶梯度信息非常接近零，所以上式的第一项也可以忽略不计。

又假设目标函数接近二次函数，所以就忽略高次项，第四项可以忽略不计。

因此，公式就简化为：$ \delta E=\frac{1}{2}\sum_i h_{ii}\delta u_i^2$

## 思考

在进行对角线近似时，本文假设参数对损失的贡献是独立的。但是由于混合偏导项的存在，可以知道多个参数在一起作用时，也许会发挥出$1+1>2$的效果。一个参数在与另一个参数一起被修剪时，可能会造成更大的损失，这种微小的损失或许在小模型上可以忽略，但是在大模型中可能不能忽略，在大模型中由于大幅值的特征出现这种损失可能会变得比较大。同样去假设目标函数接近二次函数，那也不考虑高次项，或许可以利用二阶混合偏导的值来描述两个参数之间的关联性。

得到这种关联性后，可以考虑做补偿。当剪掉一个参数后，对其关联性最大的几个参数做补偿来恢复精度。另外，由于 wanda 方法中权值乘以输入的二范数与 SparseGPT 利用二阶信息判断重要性的公式在数学上只差了个平方。所以联想到我们的这种利用二阶混合偏导的方法，是否也有一个比较简单的表示。

另外，得到参数间两两关联性，能不能推广成结构与结构之间的关联性，进行结构化剪枝，就可以替换掉 LLM-Pruner 中的仅仅用度数判断耦合结构的方法，用关联性来进行结构化剪枝。



